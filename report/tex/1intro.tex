% Introduction (your goal); 

\section{Introduction}
	One of the major domains of Artificial Intelligence is search, i.e. how a rational agent, given some sensor information and possibly some domain knowledge, searches for a goal state. Within search, there are two types of search problems. In uninformed search, the rational agent doesn't have any heuristics, i.e. it has no idea of which states are ``closer'' to the goal state. In informed search, the rational agent does have this information. 
	One classic example of informed search is A*, wherein the rational agent uses both backward cost and a heuristic function to prioritize nodes in the fringe. A* search operates under the assumption that the entire search space is known. Therefore, in applications such as robot exploration, where the entire search space is not known, the rational agent must search, carry out the generated search plan, and re-adjust (if necessary) based on discovered obstacles or other environmental factors.
	
	The goal of this research project is to understand the different types of searches that can be utilized in a ``goal-directed robot-navigation task'' in unknown terrain. In particular, this research project aims to compare these searches in terms of their intuition, implementation, and performance. The three methods that will be compared are the Naive Re-planning A* (NRA*), Lifelong Planning A* (LPA*), and D* Lite.