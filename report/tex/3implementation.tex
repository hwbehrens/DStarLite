% Implementation details for the path finding problemsas the Pacman plans and replans in the environment; figures are helpful here. 

\section{Implementation Details}\label{sec:implementation}

	All implementation was done in Python2, for ease of integration with existing systems, namely the Pacman domain. 

\subsection{Pacman}

	A common context for measuring pathfinding and route-planning algorithms is through the classic arcade game, Pacman. By adjusting different aspects of gameplay, such as the presence of ghosts, fore-knowledge of wall locations, density and placement of food pellets, and so on, a wide variety of heterogeneous environmental configurations can be used to explore different avenues of route planning.
	
	In this scenario, we assume a grid-world that can be traversed in 4 directions, $\{N, S, E, W\}$, which is surrounded by impassable barriers. The agent is unaware of any additional walls, but can observe walls immediately adjacent to it. Since there may be large numbers of walls in complex configurations, this is roughly analogous to a blind person finding their way through a labyrinth by touch, a daunting task.

\subsection{Naïve-Replanning A*}

	Naïve-Replanning A* describes a strategy where the agent first generates a shortest-path estimate to the desired goal using the well-known A* algorithm \cite{hart1968formal}, and then follows that path. As the agent moves through the partially-observable environment, if (and only if) the route is interrupted by any impassable barriers (such as walls), it updates an internal representation of the environment with that information. It then generates a new shortest path from scratch using A*, using its current location as the start location, the original goal as the new goal, and the updated environmental representation as a modified graph.
	
	This approach is called ``naïve" because it does not re-use any of the previous planning computations for later replanning, which can lead to re-exploration of many states, and unnecessarily duplicated computation. Additionally, although A* is guaranteed to find the best route given the known environmental information, NRA* is not; this is because it operates with missing information, and can lead the agent down a suboptimal path.
	
%	These characteristics provided an effective baseline for our comparison, allowing differences between possible routes found through other approaches to be easily evaluated.

\subsection{Lifelong-Planning A*}
	Lifelong Planning A* was implemented by creating a generalized implementation, then by making small changes to interface it with the Pacman domain. This was accomplished using object-oriented design principles. In particular, the LPA* object must be instantiated with the maze dimensions, the start location, and goal location. It maintains a list of so-called naive walls, which are the walls the agent is certain exist. We have implemented a mechanism with which the agent can ``make'', or learn, a wall in the naive walls so that its knowledge about the maze can be updated and persist. This wraps the LPA* object: initially supplying information, iteratively extracting path steps from the object, and supplying information about the true walls to the object. Since the LPA* agent must backtrack to compensate for the unchanging start position in LPA* (i.e. revisit parts of the maze multiple times), care had to be taken to make sure that this backtracking behavior was captured in the final path returned for visualization. Each time new information was supplied to the LPA* object, edge weights were updated, and the LPA* object would generate a new route automatically if needed.
	
	One of the challenges that the group faced with this part of the implementation was representing the search process that the Pacman took. Instead of simply returning the final path, if there was a backtracking situation, the backtrack path had to be appended to the existing path without any overlap. Rather than forcing the agent to return to the start position in these cases, we instead intersected the inverse paths to the furthest downstream point, reducing extraneous movement if possible. Extensive debugging was required to provide this functionality.
	
\subsection{D* Lite}
	Similar to the LPA* implementation, the D* Lite algorithm was also implemented in an object oriented manner. The overall search again acted as a wrapper to the D* Lite object, initializing it, and iteratively extracting information from and updating information in the object. However there was a subtle difference in how the D* Lite object operates. With the D* Lite object, since the start position corresponded to the agent's current position, we could simply take a step with the object, learn information from the perceived walls, and repeat. Therefore, no backtracking had to be taken into account because the D* Lite algorithm calculates the shortest path from the current node rather than from the start location. 
	
	Another specific challenge that the group faced with both LPA* and D* Lite integration were the initial differences between the core algorithm and Pacman domain. In particular, the core algorithm used a coordinate system that was transposed with respect to the Pacman domain. Additionally, the core implementation returned a list of coordinate points, rather than actions. Both of these discrepancies had to be accounted for in the code. Finally, the Pacman domain maintains a count of nodes expanded, each time a call to \text{get successors} is made. Since our LPA* and D* Lite core did not interact with \text{get successors}, an internal expansion count had to be maintained so that it could be tracked as a metric for evaluation.

\subsection{Test Coverage}

	To ensure correct execution of the implementations, unit tests were created in conjunction with the PyCoverage tool. These units tests were used to test the correctness of the implementations against a series of inputs and expected outputs for both the underlying algorithmic implementations, as well as the supporting data structures and algorithms used.
	
%	Additionally, these tests were useful in performing regression testing, to ensure that changes to the core algorithmic implementations necessary for integration with the Pacman domain did not compromise their underlying logic.
	
	Our test suite provided complete (100\%) coverage for all core implementations and supporting libraries which were implemented in the course of this project. Supporting code, such as that provided through the Pacman project, system libraries, or other external sources was judged as outside the scope of our testing strategy.


